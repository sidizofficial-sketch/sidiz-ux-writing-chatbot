import streamlit as st
import google.generativeai as genai

# ==========================================
# 1. ë³´ì•ˆ ì„¤ì • (Secretsì—ì„œ í‚¤ ê°€ì ¸ì˜¤ê¸°)
# ==========================================
try:
    # Streamlit Cloudì˜ Secrets ì„¤ì •ì—ì„œ í‚¤ë¥¼ ì½ì–´ì˜µë‹ˆë‹¤.
    GOOGLE_API_KEY = st.secrets["GEMINI_API_KEY"]
    genai.configure(api_key=GOOGLE_API_KEY)
except KeyError:
    st.error("Secretsì— 'GEMINI_API_KEY'ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê´€ë¦¬ì ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

# ==========================================
# 2. ë¸Œëœë“œ ê°€ì´ë“œë¼ì¸ (System Instruction)
# ==========================================
SYSTEM_INSTRUCTION = """
# To run this code you need to install the following dependencies:
# pip install google-genai

import base64
import os
from google import genai
from google.genai import types


def generate():
    client = genai.Client(
        api_key=os.environ.get("GEMINI_API_KEY"),
    )

    model = "gemini-3-flash-preview"
    contents = [
        types.Content(
            role="user",
            parts=[
                types.Part.from_text(text="""INSERT_INPUT_HERE"""),
            ],
        ),
    ]
    tools = [
        types.Tool(googleSearch=types.GoogleSearch(
        )),
    ]
    generate_content_config = types.GenerateContentConfig(
        thinking_config=types.ThinkingConfig(
            thinking_level="HIGH",
        ),
        tools=tools,
        system_instruction=[
            types.Part.from_text(text="""ë„ˆëŠ” ì‹œë””ì¦ˆì˜ UX ë¼ì´í„°ì•¼. ì¼ë°˜ì ì¸ ë¬¸êµ¬ë¥¼ ì‹œë””ì¦ˆë§Œì˜ [ì „ë¬¸ì /ì„¸ì‹¬í•œ/í˜ì‹ ì ] í†¤ìœ¼ë¡œ ë°”ê¿”ì¤˜.
ì•„ë˜ëŠ” ì‹œë””ì¦ˆ í™ˆí˜ì´ì§€ì—ì„œ ê°€ì ¸ì˜¨ ë¸Œëœë“œ ë¬¸êµ¬ë“¤ì´ì•¼. ì´ ë§íˆ¬ì™€ ë‹¨ì–´ ì„ íƒì„ í•™ìŠµí•´ì„œ ë‚´ ë¬¸ì¥ì„ ë³€í™˜í•´ì¤˜.

[ì°¸ê³  ë¬¸êµ¬]

ì‹œë””ì¦ˆì˜ ë””ìì¸ì€ ì‚¬ìš©ìë¡œë¶€í„° ì‹œì‘ë©ë‹ˆë‹¤.
ëˆ„ê°€ ì•‰ì„ì§€, ì–´ë–¤ ìƒí™©ì—ì„œ ì“°ì¼ì§€, ì–´ë–¤ ì›€ì§ì„ì´ ì˜ì ìœ„ì—ì„œ ì¼ì–´ë‚ ì§€ ëŠì„ì—†ì´ ê´€ì°°í•˜ê³  ê³ ë¯¼í•˜ì—¬ ìµœìƒì˜ ì˜ì ìœ„ ê²½í—˜ì´ë¼ëŠ” ì‹œíŒ… ì†”ë£¨ì…˜ì„ êµ¬í˜„í•´ëƒ…ë‹ˆë‹¤.

ì‹œë””ì¦ˆì˜ ì œí’ˆì€ ë‹¤ì–‘í•œ ì‚¬ëŒë“¤ì„ ë§Œë‚©ë‹ˆë‹¤.
ì‹œë””ì¦ˆëŠ” ì¸ì²´ì— ëŒ€í•œ ë‹¤ì–‘í•œ ì—°êµ¬ì™€ ê³µí•™ì  ì„¤ê³„ë¥¼ í†µí•´ ëˆ„êµ¬ë“ ì§€ í¸ì•ˆí•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì œí’ˆì„ ì™„ì„±í•©ë‹ˆë‹¤.

ì‹œë””ì¦ˆëŠ” ê¸°ìˆ ì˜ ë°œì „ì„ ì•ì„œê°‘ë‹ˆë‹¤.
ì–¸ì œë‚˜ ìƒˆë¡œìš´ ì‹œë„ë¥¼ ì£¼ì € ì•Šê³ , ìŒ“ì•„ì˜¨ ì „ë¬¸ì„±ì„ ì œí’ˆì— ë”í•´ ì˜ì ìœ„ì˜ ê°€ì¥ ì§„ë³´ëœ ê²½í—˜ì„ ë§Œë“­ë‹ˆë‹¤.

ì˜ìë¥¼ í†µí•´ ì‚¬íšŒì  ì„ ìˆœí™˜ì„ ì„¤ê³„í•©ë‹ˆë‹¤.
ì œí’ˆ ì‚¬ìš©ì— ëŒ€í•œ ì¸ì‹ ì „í™˜ê³¼, ê·¸ë¥¼ ë’·ë°›ì¹¨í•˜ëŠ” ìš°ìˆ˜í•œ ì œí’ˆë ¥, ìƒˆë¡œìš´ ìˆ˜ë¦¬ ë°©ì‹ì„ í†µí•´ ì œí’ˆ êµ¬ë§¤ê°€ ê¸°ëŠ¥ì  ê°€ì¹˜ë¥¼ ë„˜ì–´ ì§€ì†ê°€ëŠ¥ì„±ì„ ì´ë£¨ëŠ” ë°©ì‹ì´ ë˜ë„ë¡ ì±…ì„ì„ ë‹¤í•©ë‹ˆë‹¤.

ê°ˆìˆ˜ë¡ ë‹¤ì–‘í•´ì§€ëŠ” ë””ë°”ì´ìŠ¤ì™€ ì—…ë¬´ í™˜ê²½ ì†ì—ì„œ ë‹¹ì‹ ì´ ë³€í•¨ì—†ì´ ìµœìƒì˜ ëŠ¥ë ¥ì„ ë°œíœ˜í•  ìˆ˜ ìˆë„ë¡
ì–´ë–¤ ìƒí™©ê³¼ ìì„¸ì—ì„œë„ ìœ ì—°í•˜ê²Œ ë°˜ì‘í•˜ë©° ëª¨ë“  ë‹ˆì¦ˆì— ëŒ€ì‘í•˜ëŠ” í¼í¬ë¨¼ìŠ¤ ê³µí•™ ì˜ìì™€ í•¨ê»˜í•˜ì„¸ìš”."""),
        ],
    )

    for chunk in client.models.generate_content_stream(
        model=model,
        contents=contents,
        config=generate_content_config,
    ):
        print(chunk.text, end="")

if __name__ == "__main__":
    generate()

"""

# ==========================================
# 3. UI êµ¬ì„± ë° ì±„íŒ… ë¡œì§
# ==========================================
st.set_page_config(page_title="ì‹œë””ì¦ˆ UX ë²ˆì—­ê¸°", page_icon="ğŸ’º")
st.title("ğŸ’º ì‹œë””ì¦ˆ UX ë¼ì´íŒ… ë²ˆì—­ê¸°")

if "messages" not in st.session_state:
    st.session_state.messages = []

# ëŒ€í™” ë‚´ì—­ í‘œì‹œ ë° í”¼ë“œë°± ë²„íŠ¼
for i, message in enumerate(st.session_state.messages):
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if message["role"] == "assistant" and i == len(st.session_state.messages) - 1:
            # ì—„ì§€ì²™ í”¼ë“œë°± ìˆ˜ì§‘
            st.feedback("thumbs", key=f"feedback_{i}")

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ìˆ˜ì •í•  ë¬¸êµ¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        # Gemini ëª¨ë¸ í˜¸ì¶œ (System Instruction í¬í•¨)
        model = genai.GenerativeModel(
            model_name="gemini-1.5-flash",
            system_instruction=SYSTEM_INSTRUCTION
        )
        response = model.generate_content(prompt)
        st.markdown(response.text)
        st.session_state.messages.append({"role": "assistant", "content": response.text})
        st.rerun()
