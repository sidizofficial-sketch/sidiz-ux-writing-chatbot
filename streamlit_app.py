import streamlit as st
import google.generativeai as genai

# ==========================================
# 1. í˜ì´ì§€ ì„¤ì •
# ==========================================
st.set_page_config(page_title="ì‹œë””ì¦ˆ UX ë²ˆì—­ê¸°", page_icon="ğŸ’º", layout="wide")

# ==========================================
# 2. ë³´ì•ˆ ì„¤ì •
# ==========================================
try:
    GOOGLE_API_KEY = st.secrets["gemini"]["api_key"]
    genai.configure(api_key=GOOGLE_API_KEY)
    
    model_list = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
    target = next((m for m in model_list if "1.5-flash" in m), model_list[0])
    
    st.success(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {target}")
    
except KeyError:
    st.error("âŒ Secretsì— 'gemini.api_key'ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    st.stop()
except Exception as e:
    st.error(f"âŒ Gemini API ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
    st.stop()

# ==========================================
# 3. ë¸Œëœë“œ ê°€ì´ë“œë¼ì¸
# ==========================================
SYSTEM_INSTRUCTION = '''ë„ˆëŠ” ì‹œë””ì¦ˆì˜ UX ë¼ì´í„°ì•¼. ì¼ë°˜ì ì¸ ë¬¸êµ¬ë¥¼ ì‹œë””ì¦ˆë§Œì˜ [ì „ë¬¸ì /ì„¸ì‹¬í•œ/í˜ì‹ ì ] í†¤ìœ¼ë¡œ ë°”ê¿”ì¤˜.
ì•„ë˜ëŠ” ì‹œë””ì¦ˆ í™ˆí˜ì´ì§€ì—ì„œ ê°€ì ¸ì˜¨ ë¸Œëœë“œ ë¬¸êµ¬ë“¤ì´ì•¼. ì´ ë§íˆ¬ì™€ ë‹¨ì–´ ì„ íƒì„ í•™ìŠµí•´ì„œ ë‚´ ë¬¸ì¥ì„ ë³€í™˜í•´ì¤˜.

[ì°¸ê³  ë¬¸êµ¬]
- ì‹œë””ì¦ˆì˜ ë””ìì¸ì€ ì‚¬ìš©ìë¡œë¶€í„° ì‹œì‘ë©ë‹ˆë‹¤. ëˆ„ê°€ ì•‰ì„ì§€, ì–´ë–¤ ìƒí™©ì—ì„œ ì“°ì¼ì§€ ê³ ë¯¼í•˜ì—¬ ìµœìƒì˜ ì˜ì ìœ„ ê²½í—˜ì´ë¼ëŠ” ì‹œíŒ… ì†”ë£¨ì…˜ì„ êµ¬í˜„í•´ëƒ…ë‹ˆë‹¤.
- ì¸ì²´ì— ëŒ€í•œ ë‹¤ì–‘í•œ ì—°êµ¬ì™€ ê³µí•™ì  ì„¤ê³„ë¥¼ í†µí•´ ëˆ„êµ¬ë“ ì§€ í¸ì•ˆí•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì œí’ˆì„ ì™„ì„±í•©ë‹ˆë‹¤.
- ì–¸ì œë‚˜ ìƒˆë¡œìš´ ì‹œë„ë¥¼ ì£¼ì € ì•Šê³ , ì „ë¬¸ì„±ì„ ë”í•´ ì˜ì ìœ„ì˜ ê°€ì¥ ì§„ë³´ëœ ê²½í—˜ì„ ë§Œë“­ë‹ˆë‹¤.
- ì œí’ˆ êµ¬ë§¤ê°€ ê¸°ëŠ¥ì  ê°€ì¹˜ë¥¼ ë„˜ì–´ ì§€ì†ê°€ëŠ¥ì„±ì„ ì´ë£¨ëŠ” ë°©ì‹ì´ ë˜ë„ë¡ ì±…ì„ì„ ë‹¤í•©ë‹ˆë‹¤.
- ì–´ë–¤ ìƒí™©ê³¼ ìì„¸ì—ì„œë„ ìœ ì—°í•˜ê²Œ ë°˜ì‘í•˜ë©° ëª¨ë“  ë‹ˆì¦ˆì— ëŒ€ì‘í•˜ëŠ” í¼í¬ë¨¼ìŠ¤ ê³µí•™ ì˜ìì™€ í•¨ê»˜í•˜ì„¸ìš”.
'''

# ==========================================
# 4. ëª¨ë¸ ì´ˆê¸°í™”
# ==========================================
@st.cache_resource
def get_gemini_model():
    model_list = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
    target = next((m for m in model_list if "1.5-flash" in m), model_list[0])
    return genai.GenerativeModel(target)

# ==========================================
# 5. UI êµ¬ì„±
# ==========================================
st.title("ğŸ’º ì‹œë””ì¦ˆ UX ë¼ì´íŒ… ë²ˆì—­ê¸°")
st.markdown("---")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

if "feedback_data" not in st.session_state:
    st.session_state.feedback_data = {}

# ==========================================
# 6. ì‚¬ì´ë“œë°”
# ==========================================
with st.sidebar:
    st.header("ğŸ¯ ì‚¬ìš© ê°€ì´ë“œ")
    st.markdown("""
    1. ì¼ë°˜ ë¬¸êµ¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”
    2. ì‹œë””ì¦ˆ í†¤ìœ¼ë¡œ ë³€í™˜ëœ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”
    3. ë§Œì¡±ë„ë¥¼ ğŸ‘/ğŸ‘ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”
    """)
    
    st.markdown("---")
    
    st.markdown("#### ğŸ’¬ ì˜ˆì‹œ")
    st.code("í¸ì•ˆí•œ ì˜ìì…ë‹ˆë‹¤", language=None)
    st.markdown("â†“")
    st.info("ì¸ì²´ê³µí•™ì  ì„¤ê³„ë¥¼ í†µí•´ ëˆ„êµ¬ë‚˜ í¸ì•ˆí•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì‹œíŒ… ì†”ë£¨ì…˜ì…ë‹ˆë‹¤")
    
    st.markdown("---")
    
    if st.button("ğŸ—‘ï¸ ëŒ€í™” ë‚´ì—­ ì´ˆê¸°í™”"):
        st.session_state.messages = []
        st.session_state.feedback_data = {}
        st.rerun()
    
    if st.session_state.feedback_data:
        st.divider()
        st.subheader("ğŸ“Š í”¼ë“œë°± í†µê³„")
        thumbs_up = sum(1 for f in st.session_state.feedback_data.values() if f["feedback"] == 1)
        thumbs_down = sum(1 for f in st.session_state.feedback_data.values() if f["feedback"] == 0)
        st.metric("ê¸ì •", thumbs_up)
        st.metric("ë¶€ì •", thumbs_down)

# ==========================================
# 7. ì´ˆê¸° ì•ˆë‚´ ë©”ì‹œì§€ (ëŒ€í™” ê¸°ë¡ì´ ì—†ì„ ë•Œë§Œ)
# ==========================================
if len(st.session_state.messages) == 0:
    st.info("ğŸ‘‡ **ì•„ë˜ ì…ë ¥ì°½ì— ì¼ë°˜ ë¬¸êµ¬ë¥¼ ì…ë ¥í•˜ë©´ ì‹œë””ì¦ˆ ë¸Œëœë“œ í†¤ìœ¼ë¡œ ë³€í™˜í•´ë“œë¦½ë‹ˆë‹¤!**")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("### ğŸ“ Before")
        st.code("í¸ì•ˆí•œ ì˜ìì…ë‹ˆë‹¤")
    
    with col2:
        st.markdown("### â¡ï¸")
    
    with col3:
        st.markdown("### âœ¨ After")
        st.success("ì¸ì²´ê³µí•™ì  ì„¤ê³„ë¥¼ í†µí•´ ëˆ„êµ¬ë‚˜ í¸ì•ˆí•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì‹œíŒ… ì†”ë£¨ì…˜ì…ë‹ˆë‹¤")

# ==========================================
# 8. ëŒ€í™” ë‚´ì—­ í‘œì‹œ
# ==========================================
for i, message in enumerate(st.session_state.messages):
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        
        if message["role"] == "assistant" and i == len(st.session_state.messages) - 1:
            feedback = st.feedback("thumbs", key=f"feedback_{i}")
            
            if feedback is not None:
                st.session_state.feedback_data[i] = {
                    "message": message["content"],
                    "feedback": feedback,
                    "prompt": st.session_state.messages[i-1]["content"] if i > 0 else ""
                }

# ==========================================
# 9. ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
# ==========================================
st.markdown("---")
st.markdown("### ğŸ’¬ ë¬¸êµ¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”")

prompt = st.chat_input("ì˜ˆ: í¸ì•ˆí•œ ì˜ìì…ë‹ˆë‹¤", key="main_input")

if prompt:
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    with st.chat_message("user"):
        st.markdown(prompt)
    
    with st.chat_message("assistant"):
        try:
            model = get_gemini_model()
            full_prompt = f"{SYSTEM_INSTRUCTION}\n\nì‚¬ìš©ì ìš”ì²­: {prompt}"
            
            with st.spinner("ì‹œë””ì¦ˆ í†¤ìœ¼ë¡œ ë³€í™˜ ì¤‘..."):
                response = model.generate_content(full_prompt)
                assistant_message = response.text
            
            st.markdown(assistant_message)
            st.session_state.messages.append({"role": "assistant", "content": assistant_message})
            
        except Exception as e:
            error_str = str(e)
            
            if "429" in error_str or "quota" in error_str.lower():
                st.error("â±ï¸ **Gemini API í• ë‹¹ëŸ‰ ì´ˆê³¼**")
                st.warning("ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            else:
                st.error(f"âŒ ì˜¤ë¥˜: {error_str}")
            
            error_message = "ì¼ì‹œì ìœ¼ë¡œ ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            st.session_state.messages.append({"role": "assistant", "content": error_message})
    
    st.rerun()
